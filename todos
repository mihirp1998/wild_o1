add multi gpu support
multirun support via hydra?
add support to only train special tokens
parallelize the get_perplexity function, currently batch size is 1 hardcoded there
setup server
fix bug in the train data generated by lili of multiple sentences in a single example
