# Training and evaluation arguments
causal_llm: true
learning_rate: 2.0e-3
num_train_epochs: 2000
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
save_strategy: "best"
gradient_checkpointing: true
logging_steps: 25
save_steps: 2500
packing: false
save_total_limit: 1
model_name: "meta-llama/Llama-3.1-8B"
output_dir: "${oc.env:CKPT_DIR}"
load_exp: null
use_special_tokens: true
use_existing: false
eval_strategy: "steps"
push_to_hub: false
rand_train: false
use_n_shot_prompt: 0
max_new_tokens: 400
num_samples: 20
generate_every_n_steps: 500
max_seq_length: 1024
weight_decay: 0.0
prompt_version: 3
perplexity_device: 1
debug_with_single_example: false
eval_steps: 500
tune_special_tokens: true
tune_only_lora: false
skip_first_step: false
num_special_tokens: 2
# PEFT arguments
use_incontext: true
use_peft: true
lora_r: 32
lora_alpha: 16
